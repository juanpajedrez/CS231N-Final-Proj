{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densenet121 Pre trained to test\n",
    "\n",
    "This jupyter notebook has the objective to, not only retrieve the accuracies of the Densenet121 pretrained, but to obtain also <br>\n",
    "the layer features before the last classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Import necessary modules\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # Set default size of plots.\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to here\n",
    "\n",
    "Make sure the setup the paths properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abhishekkumar/Projects/cs231n/CS231N-Final-Proj/notebooks\n"
     ]
    }
   ],
   "source": [
    "#Path to assign tests (copy path directly)\n",
    "notebooks_path = os.getcwd() # OR MAYBE has to be set manually depending your computer\n",
    "\n",
    "#Set the path to this working directory\n",
    "os.chdir(notebooks_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "#Append the path the src folder\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir, \"src\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary module for downloading\n",
    "\n",
    "Note for this: EVERYTIME There is a change inside the download <br>\n",
    "the changes inside the file would only be shown if the jupyter kernel is restarted. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from utils import CXReader, DfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_path: /Users/abhishekkumar/Projects/cs231n/CS231N-Final-Proj/notebooks/../meta, \n",
      "data_path: /Users/abhishekkumar/Projects/cs231n/cxr14/images\n"
     ]
    }
   ],
   "source": [
    "# Create the data path\n",
    "df_path = os.path.join(notebooks_path, os.pardir, \"meta\")\n",
    "\n",
    "# If the environment is defined, prefer that over the local path\n",
    "if \"DATA_PATH\" in os.environ:\n",
    "    data_path = os.environ[\"DATA_PATH\"]\n",
    "data_path = data_path or os.path.join(df_path, \"images\")\n",
    "print(f'df_path: {df_path}, \\ndata_path: {data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataframes of the data\n",
    "First, lets obtain the dataframes for the data and check that all metadata <br>\n",
    "information has been set up properly. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 37.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: val.csv has been retrieved\n",
      "The file: test.csv has been retrieved\n",
      "The file: train.csv has been retrieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe compiler\n",
    "df_compiler = DfReader()\n",
    "\n",
    "#set the path and retrieve the dataframes\n",
    "df_compiler.set_folder_path(df_path)\n",
    "\n",
    "#Get the dataframe holder and names\n",
    "dfs_holder, dfs_names = df_compiler.get_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the images and labels\n",
    "\n",
    "Also, obtain DataLoaders for test, train, and validation datasets using <br>\n",
    "the Dataloader class from pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Dataset Information====\n",
      "Total training samples 78506\n",
      "Total training samples 21081\n",
      "Total training samples 12533\n",
      "====Dataset Information====\n",
      "\n",
      "\n",
      "====Sample Data====\n",
      "Image: torch.Size([3, 224, 224]), labels: torch.Size([15])\n",
      "====Sample Data====\n",
      "\n",
      "\n",
      "batch number: 0\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "batch number: 1\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "batch number: 2\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "batch number: 3\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "batch number: 4\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "batch number: 5\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 15])\n",
      "It can iterate through all batches\n"
     ]
    }
   ],
   "source": [
    "# Get the device if cuda or not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define a transformations for the VGGnet16 (requires a 224,224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize to 256x256\n",
    "    transforms.CenterCrop((224, 224)),  # Center crop to 224x224\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Create datasets and dataloaders\n",
    "train_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[dfs_names.index('train.csv')], transform=transform,device=device)\n",
    "test_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[dfs_names.index('test.csv')], transform=transform, device=device)\n",
    "val_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[dfs_names.index('val.csv')], transform=transform, device=device)\n",
    "\n",
    "#Sampled images from train to see single shape\n",
    "sample_image, sample_label = train_dataset[1]\n",
    "print(\"====Dataset Information====\")\n",
    "print(\"Total training samples\", len(train_dataset))\n",
    "print(\"Total training samples\", len(test_dataset))\n",
    "print(\"Total training samples\", len(val_dataset))\n",
    "print(\"====Dataset Information====\\n\\n\")\n",
    "print(\"====Sample Data====\")\n",
    "print(f\"Image: {sample_image.shape}, labels: {sample_label.shape}\")\n",
    "print(\"====Sample Data====\\n\\n\")\n",
    "\n",
    "# With batch size of 32, and shuffle true, and num workers = 4\n",
    "batch_size = 32\n",
    "\n",
    "# Set the number of workers on local machine to be 0 for debugging\n",
    "if os.environ.get(\"NUM_WORKERS\"):\n",
    "    num_workers = int(os.environ.get(\"NUM_WORKERS\"))\n",
    "else:\n",
    "    num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "#Iterate inside a batch\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    print(f\"batch number: {idx}\")\n",
    "    images, labels = batch\n",
    "    print(\"Shape of batch of images and labels\")\n",
    "    print(f\"Images: {images.shape}, labels: {labels.shape}\")\n",
    "    if idx == 5:\n",
    "        print(\"It can iterate through all batches\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the densenet121 pretrained model\n",
    "\n",
    "Check if you have GPU Envidia! Else, use the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained model\n",
    "densenet121 = models.densenet121(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the densenet121.features architecture and get the parameter shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace=True)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "[torch.Size([64, 3, 7, 7]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([64]), torch.Size([128, 64, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([96]), torch.Size([96]), torch.Size([128, 96, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([128]), torch.Size([128]), torch.Size([128, 128, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([160]), torch.Size([160]), torch.Size([128, 160, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([128, 192, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([224]), torch.Size([224]), torch.Size([128, 224, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([256]), torch.Size([256]), torch.Size([128, 256, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([128, 128, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([160]), torch.Size([160]), torch.Size([128, 160, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([128, 192, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([224]), torch.Size([224]), torch.Size([128, 224, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([256]), torch.Size([256]), torch.Size([128, 256, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([288]), torch.Size([288]), torch.Size([128, 288, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([320]), torch.Size([320]), torch.Size([128, 320, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([352]), torch.Size([352]), torch.Size([128, 352, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([384]), torch.Size([384]), torch.Size([128, 384, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([416]), torch.Size([416]), torch.Size([128, 416, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([448]), torch.Size([448]), torch.Size([128, 448, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([480]), torch.Size([480]), torch.Size([128, 480, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([512]), torch.Size([512]), torch.Size([256, 512, 1, 1]), torch.Size([256]), torch.Size([256]), torch.Size([128, 256, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([288]), torch.Size([288]), torch.Size([128, 288, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([320]), torch.Size([320]), torch.Size([128, 320, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([352]), torch.Size([352]), torch.Size([128, 352, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([384]), torch.Size([384]), torch.Size([128, 384, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([416]), torch.Size([416]), torch.Size([128, 416, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([448]), torch.Size([448]), torch.Size([128, 448, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([480]), torch.Size([480]), torch.Size([128, 480, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([512]), torch.Size([512]), torch.Size([128, 512, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([544]), torch.Size([544]), torch.Size([128, 544, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([576]), torch.Size([576]), torch.Size([128, 576, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([608]), torch.Size([608]), torch.Size([128, 608, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([640]), torch.Size([640]), torch.Size([128, 640, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([672]), torch.Size([672]), torch.Size([128, 672, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([704]), torch.Size([704]), torch.Size([128, 704, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([736]), torch.Size([736]), torch.Size([128, 736, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([768]), torch.Size([768]), torch.Size([128, 768, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([800]), torch.Size([800]), torch.Size([128, 800, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([832]), torch.Size([832]), torch.Size([128, 832, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([864]), torch.Size([864]), torch.Size([128, 864, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([896]), torch.Size([896]), torch.Size([128, 896, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([928]), torch.Size([928]), torch.Size([128, 928, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([960]), torch.Size([960]), torch.Size([128, 960, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([992]), torch.Size([992]), torch.Size([128, 992, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([1024]), torch.Size([1024]), torch.Size([512, 1024, 1, 1]), torch.Size([512]), torch.Size([512]), torch.Size([128, 512, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([544]), torch.Size([544]), torch.Size([128, 544, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([576]), torch.Size([576]), torch.Size([128, 576, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([608]), torch.Size([608]), torch.Size([128, 608, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([640]), torch.Size([640]), torch.Size([128, 640, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([672]), torch.Size([672]), torch.Size([128, 672, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([704]), torch.Size([704]), torch.Size([128, 704, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([736]), torch.Size([736]), torch.Size([128, 736, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([768]), torch.Size([768]), torch.Size([128, 768, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([800]), torch.Size([800]), torch.Size([128, 800, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([832]), torch.Size([832]), torch.Size([128, 832, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([864]), torch.Size([864]), torch.Size([128, 864, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([896]), torch.Size([896]), torch.Size([128, 896, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([928]), torch.Size([928]), torch.Size([128, 928, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([960]), torch.Size([960]), torch.Size([128, 960, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([992]), torch.Size([992]), torch.Size([128, 992, 1, 1]), torch.Size([128]), torch.Size([128]), torch.Size([32, 128, 3, 3]), torch.Size([1024]), torch.Size([1024])]\n"
     ]
    }
   ],
   "source": [
    "print(densenet121.features)\n",
    "print([x.shape for x in densenet121.features.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the densenet121 classifier parameters and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1024, out_features=1000, bias=True)\n",
      "[torch.Size([1000, 1024]), torch.Size([1000])]\n"
     ]
    }
   ],
   "source": [
    "print(densenet121.classifier)\n",
    "print([x.shape for x in densenet121.classifier.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE CELL to conduct fine-tuning on Vggnet16 only on the last (Linear) layer\n",
    "\n",
    "# First, freeze all the parameters\n",
    "for param in densenet121.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "# Modify the last layer for the last 20 classes\n",
    "num_classes = sample_label.shape[0]  # Number of classes for your specific task\n",
    "num_features = densenet121.classifier.in_features #Get all of the features after convolutional layers\n",
    "\n",
    "print(num_classes)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.plot import visualise_weights\n",
    "\n",
    "# visualise the weights of the first layer\n",
    "weights = densenet121.features.conv0.weight.data.cpu().numpy()\n",
    "visualise_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Obtain the same classifier you got befor with lower number of classes, so we can pretrain it\n",
    "# Since we are using cross entropy loss, we don't need to add an activation at the end\n",
    "dropout_p = 0.1\n",
    "densenet121.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 4096, bias=True),\n",
    "    nn.ReLU(inplace= True),\n",
    "    nn.Dropout(dropout_p, inplace=False),\n",
    "    nn.Linear(4096, 4096, bias=True),\n",
    "    nn.ReLU(inplace= True),\n",
    "    nn.Dropout(dropout_p, inplace=False),\n",
    "    nn.Linear(4096, num_classes, bias=True)\n",
    ")\n",
    "\n",
    "print(densenet121.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abhishekkumar/Projects/cs231n/CS231N-Final-Proj/notebooks/../models\n"
     ]
    }
   ],
   "source": [
    "# Create state_dict path\n",
    "model_dict_path = os.path.join(notebooks_path, os.pardir, \"models\")\n",
    "\n",
    "if os.path.exists(model_dict_path) == False:\n",
    "    os.mkdir(model_dict_path)\n",
    "print(model_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "# Create the weights for the loss function\n",
    "# The weights are the inverse of the class frequency\n",
    "# This is to account for the class imbalance\n",
    "# Lets get the frequencies of the classes in the training set\n",
    "train_df = dfs_holder[dfs_names.index('train.csv')]\n",
    "class_frequencis = torch.tensor(train_df[train_df.columns[1:-1]].sum().values)\n",
    "weights = 1.0 / class_frequencis\n",
    "weights = weights / weights.sum()\n",
    "criterion = nn.CrossEntropyLoss(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: Linear\n",
      "  weight: torch.Size([4096, 1024])\n",
      "  bias: torch.Size([4096])\n",
      "Layer 1: ReLU\n",
      "Layer 2: Dropout\n",
      "Layer 3: Linear\n",
      "  weight: torch.Size([4096, 4096])\n",
      "  bias: torch.Size([4096])\n",
      "Layer 4: ReLU\n",
      "Layer 5: Dropout\n",
      "Layer 6: Linear\n",
      "  weight: torch.Size([15, 4096])\n",
      "  bias: torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "# Optimiser\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = densenet121\n",
    "\n",
    "# we are updating the below parameters\n",
    "for i, layer in enumerate(model.classifier.children()):\n",
    "    print(f\"Layer {i}: {layer.__class__.__name__}\")\n",
    "    for name, param in layer.named_parameters():\n",
    "        print(f\"  {name}: {param.size()}\")\n",
    "\n",
    "optimizer = Adam(model.classifier.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = bool(os.environ.get('USE_WANDB', False))\n",
    "if use_wandb:\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "def convert_scores_to_class_predictions(scores):\n",
    "    # ToDo: The class scores need to be converted to class predictions\n",
    "    # predict labels\n",
    "    # labels = (scores > threshold).float()\n",
    "    # return labels\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy(loader, model):\n",
    "    # ToDo: add train flag in the dataset\n",
    "    # if loader.dataset.train:\n",
    "    #     print('Checking accuracy on validation set')\n",
    "    # else:\n",
    "    #     print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            labels = labels.to(device=device, dtype=torch.float32)\n",
    "            scores = model(images)\n",
    "\n",
    "            labels = convert_scores_to_class_predictions(scores)\n",
    "\n",
    "            # ToDo: Determine a method to convert the scores to class predictions\n",
    "        #     _, preds = scores.max(1)\n",
    "        #     num_correct += (preds == y).sum()\n",
    "        #     num_samples += preds.size(0)\n",
    "        # acc = float(num_correct) / num_samples\n",
    "        # print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    # return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, data_loader, num_epochs, device:str):\n",
    "    # Initialize wandb\n",
    "    if use_wandb:\n",
    "        wandb.init(\n",
    "            project=\"cs231-project\", \n",
    "            name=\"densenet121-finetune-adam\",\n",
    "            config={\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"lr\": 0.001,\n",
    "                \"batch_size\": 16,\n",
    "                \"num_classes\": 14,\n",
    "                \"dropout_p\": 0.1\n",
    "            }\n",
    "        )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-------------')\n",
    "            \n",
    "        for t, (images, labels) in enumerate(data_loader):\n",
    "\n",
    "            # Convert labels to float type (also need to move to CUDA again!)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "            images = images.to(device, dtype=torch.float32)\n",
    "\n",
    "            model = densenet121.to(device)\n",
    "            model.train()\n",
    "            \n",
    "            # forward pass\n",
    "            scores = model(images)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(scores, labels)\n",
    "\n",
    "            # zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # ToDo: Plot the evaluation matrix like confusion matrix, ROC curve, etc.\n",
    "            \n",
    "            # pred_labels = convert_scores_to_class_predictions(scores)\n",
    "\n",
    "            # # Calculate TP, FP, TN, FN and accuracy\n",
    "            # TP = torch.sum((pred_labels == 1) & (labels == 1)).item()\n",
    "            # FP = torch.sum((pred_labels == 1) & (labels == 0)).item()\n",
    "            # TN = torch.sum((pred_labels == 0) & (labels == 0)).item()\n",
    "            # FN = torch.sum((pred_labels == 0) & (labels == 1)).item()\n",
    "            # accuracy = ((TP + TN) / (TP + FP + TN + FN)) * 100.0                \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # ToDo: Once figure out a way to get the validation score, also step the scheduler\n",
    "\n",
    "            wandb.log({\"train_loss\": loss.item()})\n",
    "\n",
    "            if t % 1 == 0:\n",
    "                print('Epoch: {}, Iteration {}, Loss: {}'.format(epoch, t, loss.item()))\n",
    "                \n",
    "        \n",
    "        # Save parameters for each epoch\n",
    "        torch.save(model.state_dict(), os.path.join(model_dict_path, \"densenet121_finetune_params.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pq13smko) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0430ba0b5f41fd9672780d75db2bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▄█▅▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.04744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">densenet121-finetune-adam</strong> at: <a href='https://wandb.ai/a6kme_org/cs231-project/runs/pq13smko' target=\"_blank\">https://wandb.ai/a6kme_org/cs231-project/runs/pq13smko</a><br/> View project at: <a href='https://wandb.ai/a6kme_org/cs231-project' target=\"_blank\">https://wandb.ai/a6kme_org/cs231-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_153033-pq13smko/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pq13smko). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c3252f02f14219ae38e0a6d268f00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011130226389246269, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/abhishekkumar/Projects/cs231n/CS231N-Final-Proj/notebooks/wandb/run-20240513_153131-y04w7lxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/a6kme_org/cs231-project/runs/y04w7lxp' target=\"_blank\">densenet121-finetune-adam</a></strong> to <a href='https://wandb.ai/a6kme_org/cs231-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/a6kme_org/cs231-project' target=\"_blank\">https://wandb.ai/a6kme_org/cs231-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/a6kme_org/cs231-project/runs/y04w7lxp' target=\"_blank\">https://wandb.ai/a6kme_org/cs231-project/runs/y04w7lxp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "-------------\n",
      "Epoch: 0, Iteration 0, Loss: 0.06285861134529114\n",
      "Epoch: 0, Iteration 1, Loss: 0.10713343322277069\n",
      "Epoch: 0, Iteration 2, Loss: 0.08035506308078766\n",
      "Epoch: 0, Iteration 3, Loss: 0.07719867676496506\n",
      "Epoch: 0, Iteration 4, Loss: 0.06268274039030075\n",
      "Epoch: 0, Iteration 5, Loss: 0.07041128724813461\n",
      "Epoch: 0, Iteration 6, Loss: 0.10537498444318771\n",
      "Epoch: 0, Iteration 7, Loss: 0.08273983746767044\n",
      "Epoch: 0, Iteration 8, Loss: 0.07018682360649109\n",
      "Epoch: 0, Iteration 9, Loss: 0.047560326755046844\n",
      "Epoch: 0, Iteration 10, Loss: 0.09859970211982727\n",
      "Epoch: 0, Iteration 11, Loss: 0.07644838094711304\n",
      "Epoch: 0, Iteration 12, Loss: 0.09998077899217606\n",
      "Epoch: 0, Iteration 13, Loss: 0.06319418549537659\n",
      "Epoch: 0, Iteration 14, Loss: 0.04194164648652077\n",
      "Epoch: 0, Iteration 15, Loss: 0.06961403042078018\n",
      "Epoch: 0, Iteration 16, Loss: 0.03803012892603874\n",
      "Epoch: 0, Iteration 17, Loss: 0.07262994349002838\n",
      "Epoch: 0, Iteration 18, Loss: 0.01733304187655449\n",
      "Epoch: 0, Iteration 19, Loss: 0.11592385917901993\n",
      "Epoch: 0, Iteration 20, Loss: 0.0364491306245327\n",
      "Epoch: 0, Iteration 21, Loss: 0.04141104221343994\n",
      "Epoch: 0, Iteration 22, Loss: 0.055636871606111526\n",
      "Epoch: 0, Iteration 23, Loss: 0.06237395852804184\n",
      "Epoch: 0, Iteration 24, Loss: 0.07618787884712219\n",
      "Epoch: 0, Iteration 25, Loss: 0.07416030019521713\n",
      "Epoch: 0, Iteration 26, Loss: 0.07698184251785278\n",
      "Epoch: 0, Iteration 27, Loss: 0.05841655284166336\n",
      "Epoch: 0, Iteration 28, Loss: 0.08617832511663437\n",
      "Epoch: 0, Iteration 29, Loss: 0.04572424292564392\n",
      "Epoch: 0, Iteration 30, Loss: 0.05909903347492218\n",
      "Epoch: 0, Iteration 31, Loss: 0.08291520178318024\n",
      "Epoch: 0, Iteration 32, Loss: 0.10714176297187805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Let's do fine-tuning\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m finetune_model(model\u001b[38;5;241m=\u001b[39mmodel, data_loader\u001b[38;5;241m=\u001b[39mtrain_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[50], line 30\u001b[0m, in \u001b[0;36mfinetune_model\u001b[0;34m(model, data_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures(x)\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m layer(features)\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torchvision/models/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_function(prev_features)\n\u001b[1;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torchvision/models/densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(concated_features)))  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/cs231n-project/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's do fine-tuning\n",
    "finetune_model(model=model, data_loader=train_loader, num_epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "densenet121.load_state_dict(torch.load(os.path.join(model_dict_path, \"vgg16_finetune_params.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that would evaluate the model.\n",
    "\n",
    "Make sure it outputs all of the accuracies of all 20 conditions. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, data_loader, limit:int, device:str):\n",
    "    \"\"\"\n",
    "    Instance method that would evaluate with a given\n",
    "    data loader, the accuracies obtained by the VGGNET16\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    threshold = 0.5\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    #Use no grad to not perform backpropagation for inference time\n",
    "    with torch.no_grad():\n",
    "        #Iterate through each of the images and labels\n",
    "        \n",
    "        # Calculate the total numbers for metrics\n",
    "        TP, FP, TN, FN = 0.0, 0.0, 0.0, 0.0\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "    \n",
    "            #See if it works\n",
    "            images_inputs, images_labels = batch\n",
    "            images_inputs, images_labels = images_inputs.to(device), images_labels.to(device)\n",
    "\n",
    "            #Print the shape of each one of them\n",
    "            print(f\"Inputs shape: {images_inputs.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "            #Send the outputs to model in device\n",
    "            outputs = model(images_inputs)\n",
    "\n",
    "            #Binarize the output with threshold\n",
    "            pred_labels = (outputs > threshold).float()\n",
    "\n",
    "            # Calculate batch-wise TP, FP, TN, FN\n",
    "            b_TP = torch.sum((pred_labels == 1) & (images_labels == 1)).item()\n",
    "            b_FP = torch.sum((pred_labels == 1) & (images_labels == 0)).item()\n",
    "            b_TN = torch.sum((pred_labels == 0) & (images_labels == 0)).item()\n",
    "            b_FN = torch.sum((pred_labels == 0) & (images_labels == 1)).item()\n",
    "            TP += b_TP\n",
    "            FP += b_FP\n",
    "            TN += b_TN\n",
    "            FN += b_FN\n",
    "\n",
    "        #_, predicted = torch.max(outputs, 1)  # Get the index of the maximum log-probability\n",
    "        accuracy = ((TP + TN) / (TP + FP + TN + FN)) * 100.0\n",
    "        precision = (TP / (TP + FP)) * 100.0 if (TP + FP) > 0 else 0.0\n",
    "        recall = (TP / (TP + FN)) * 100.0 if (TP + FN) > 0 else 0.0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
    "        print(\"Precision: {:.2f}%\".format(precision))\n",
    "        print(\"Recall: {:.2f}%\".format(recall))\n",
    "        print(\"F1 Score: {:.2f}%\".format(f1_score))\n",
    "\n",
    "            # accuracies.append(accuracy)\n",
    "            # precisions.append(precision)\n",
    "            # recalls.append(recall)\n",
    "            # f1_scores.append(f1_score)\n",
    "\n",
    "            # if idx == limit:\n",
    "            #     print(\"Limit reached\")\n",
    "            #     break\n",
    "    return accuracies, precisions, recalls, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([25, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Accuracy: 51.61%\n",
      "Precision: 8.31%\n",
      "Recall: 54.95%\n",
      "F1 Score: 14.44%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the eval set\n",
    "accuracies, precisions, recalls, f1_scores = evaluate_model(model, test_loader, 5, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n-project",
   "language": "python",
   "name": "cs231n-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
